# å‡çº§æŒ‡å— v2.0

## ğŸ‰ æ–°åŠŸèƒ½æ¦‚è§ˆ

v2.0ç‰ˆæœ¬å¸¦æ¥äº†å…¨é¢çš„æ¶æ„ä¼˜åŒ–å’ŒåŠŸèƒ½å¢å¼ºï¼Œæä¾›æ›´é«˜æ•ˆã€æ›´çµæ´»çš„æµ‹è¯•ä½“éªŒã€‚

---

## ğŸ†• ä¸»è¦æ–°å¢åŠŸèƒ½

### 1. ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ

**åŠŸèƒ½**ï¼š
- åˆ†çº§æ—¥å¿—ï¼ˆDEBUG/INFO/WARNING/ERROR/CRITICALï¼‰
- æ—¥å¿—æ–‡ä»¶è‡ªåŠ¨è½®è½¬
- ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.utils.logger import get_logger

logger = get_logger(log_file='test.log')
logger.info("æµ‹è¯•å¼€å§‹")
logger.error("å‘ç”Ÿé”™è¯¯", error_code="HTTP_403")
```

---

### 2. YAMLé…ç½®æ–‡ä»¶æ”¯æŒ

**åŠŸèƒ½**ï¼š
- é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®
- æ”¯æŒç¯å¢ƒå˜é‡
- å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆçº§æœ€é«˜

**ä½¿ç”¨æ–¹æ³•**ï¼š

1. ç”Ÿæˆé…ç½®æ¨¡æ¿ï¼š
```bash
python -c "from llmct.utils.config import Config; Config.create_template()"
```

2. ç¼–è¾‘`config.yaml`ï¼š
```yaml
api:
  key: ${LLMCT_API_KEY}
  base_url: https://api.openai.com
  timeout: 30

testing:
  only_failed: true
  max_failures: 3

performance:
  concurrent: 10
  rate_limit_rpm: 60
```

3. ä½¿ç”¨é…ç½®ï¼š
```python
from llmct.utils.config import Config

config = Config('config.yaml')
api_key = config.get('api.key')
```

---

### 3. æ™ºèƒ½å¼‚å¸¸å¤„ç†å’Œé‡è¯•

**åŠŸèƒ½**ï¼š
- è‡ªå®šä¹‰å¼‚å¸¸ç±»å‹
- æ™ºèƒ½é‡è¯•æœºåˆ¶
- æŒ‡æ•°é€€é¿ç­–ç•¥

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.utils.retry import retry_on_exception
from llmct.core.exceptions import RateLimitError

@retry_on_exception(
    exceptions=(RateLimitError,),
    max_attempts=3,
    delay=2.0,
    backoff=2.0
)
def test_model(model_id):
    # æµ‹è¯•é€»è¾‘
    pass
```

---

### 4. å¼‚æ­¥å¹¶å‘æµ‹è¯• âš¡

**åŠŸèƒ½**ï¼š
- å¹¶å‘æµ‹è¯•å¤šä¸ªæ¨¡å‹
- å¯é…ç½®å¹¶å‘æ•°
- **æ€§èƒ½æå‡60-80%**

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.core.async_tester import test_models_async

results = test_models_async(
    api_key="your-key",
    base_url="https://api.openai.com",
    models=models_list,
    model_types=model_types_dict,
    max_concurrent=10
)
```

**æ€§èƒ½å¯¹æ¯”**ï¼š
- ä¼ ç»Ÿä¸²è¡Œï¼š25åˆ†é’Ÿæµ‹è¯•1132ä¸ªæ¨¡å‹
- å¹¶å‘æµ‹è¯•ï¼š5-8åˆ†é’Ÿæµ‹è¯•1132ä¸ªæ¨¡å‹
- **æå‡70%+**

---

### 5. æ™ºèƒ½é€Ÿç‡é™åˆ¶

**åŠŸèƒ½**ï¼š
- è‡ªåŠ¨æ§åˆ¶è¯·æ±‚é¢‘ç‡
- é¿å…è§¦å‘APIé™åˆ¶
- è‡ªé€‚åº”é€Ÿç‡è°ƒæ•´

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.utils.rate_limiter import RateLimiter, AdaptiveRateLimiter

# åŸºç¡€é€Ÿç‡é™åˆ¶
limiter = RateLimiter(max_calls=60, period=60.0)
limiter.wait_if_needed()

# è‡ªé€‚åº”é€Ÿç‡é™åˆ¶
adaptive_limiter = AdaptiveRateLimiter(initial_rpm=60)
adaptive_limiter.wait_if_needed()
adaptive_limiter.report_rate_limit()  # é‡åˆ°429æ—¶è°ƒç”¨
adaptive_limiter.report_success()  # æˆåŠŸæ—¶è°ƒç”¨
```

---

### 6. å¤šç§è¾“å‡ºæ ¼å¼æ”¯æŒ

**åŠŸèƒ½**ï¼š
- TXTï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰
- JSONï¼ˆç»“æ„åŒ–æ•°æ®ï¼‰
- CSVï¼ˆExcelå‹å¥½ï¼‰
- HTMLï¼ˆå¯è§†åŒ–æŠ¥å‘Šï¼‰

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.core.reporter import Reporter

reporter = Reporter(base_url="https://api.openai.com")

# ä¿å­˜ä¸ºä¸åŒæ ¼å¼
reporter.save_json(results, 'output.json')
reporter.save_csv(results, 'output.csv')
reporter.save_html(results, 'output.html')
```

**HTMLæŠ¥å‘Šç‰¹ç‚¹**ï¼š
- å“åº”å¼è®¾è®¡
- å½©è‰²ç»Ÿè®¡å¡ç‰‡
- äº¤äº’å¼è¡¨æ ¼
- å¯æ‰“å°å‹å¥½

---

### 7. ç»“æœå¯¹æ¯”åˆ†æ

**åŠŸèƒ½**ï¼š
- å¯¹æ¯”ä¸¤æ¬¡æµ‹è¯•ç»“æœ
- è¯†åˆ«æ–°å¢å¤±è´¥å’Œæ¢å¤çš„æ¨¡å‹
- è¶‹åŠ¿åˆ†æ

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.core.analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()

# å¯¹æ¯”ä¸¤æ¬¡æµ‹è¯•
comparison = analyzer.compare_results('test1.json', 'test2.json')

print(f"æ–°å¢å¤±è´¥: {comparison['summary']['newly_failed_count']}")
print(f"æ¢å¤æ­£å¸¸: {comparison['summary']['recovered_count']}")

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
for model in comparison['newly_failed']:
    print(f"æ¨¡å‹ {model['model']} å¤±è´¥ï¼Œé”™è¯¯: {model['new_error']}")
```

---

### 8. å¥åº·åº¦è¯„åˆ†ç³»ç»Ÿ

**åŠŸèƒ½**ï¼š
- ç»¼åˆè¯„ä¼°APIå¥åº·åº¦ï¼ˆ0-100åˆ†ï¼‰
- å¤šç»´åº¦è¯„åˆ†ï¼ˆæˆåŠŸç‡/å“åº”é€Ÿåº¦/ç¨³å®šæ€§ï¼‰
- A-Fç­‰çº§è¯„å®š

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.core.analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()
health = analyzer.calculate_health_score(results)

print(f"å¥åº·åº¦è¯„åˆ†: {health['score']}/100")
print(f"è¯„çº§: {health['grade']}")
print(f"æˆåŠŸç‡: {health['details']['success_rate']}%")
print(f"å¹³å‡å“åº”æ—¶é—´: {health['details']['avg_response_time']}ç§’")
```

**è¯„åˆ†æ ‡å‡†**ï¼š
- 90-100åˆ†: Açº§ï¼ˆä¼˜ç§€ï¼‰
- 80-89åˆ†: Bçº§ï¼ˆè‰¯å¥½ï¼‰
- 70-79åˆ†: Cçº§ï¼ˆä¸€èˆ¬ï¼‰
- 60-69åˆ†: Dçº§ï¼ˆè¾ƒå·®ï¼‰
- <60åˆ†: Fçº§ï¼ˆå¾ˆå·®ï¼‰

---

### 9. ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

**åŠŸèƒ½**ï¼š
- è‡ªåŠ¨æ£€æµ‹å¼‚å¸¸æƒ…å†µ
- å¯é…ç½®å‘Šè­¦é˜ˆå€¼
- åˆ†çº§å‘Šè­¦ï¼ˆhigh/medium/lowï¼‰

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from llmct.core.analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()

# ä½¿ç”¨é»˜è®¤é˜ˆå€¼
alerts = analyzer.check_alerts(results)

# è‡ªå®šä¹‰é˜ˆå€¼
custom_thresholds = {
    'min_success_rate': 0.7,
    'max_429_errors': 30
}
alerts = analyzer.check_alerts(results, custom_thresholds)

# å¤„ç†å‘Šè­¦
for alert in alerts:
    print(f"[{alert['severity'].upper()}] {alert['message']}")
```

**é»˜è®¤å‘Šè­¦é˜ˆå€¼**ï¼š
- æœ€ä½æˆåŠŸç‡: 50%
- æœ€å¤§å¹³å‡å“åº”æ—¶é—´: 5ç§’
- æœ€å¤š429é”™è¯¯: 50ä¸ª
- æœ€å¤š403é”™è¯¯: 100ä¸ª
- æœ€å¤šè¶…æ—¶é”™è¯¯: 20ä¸ª

---

## ğŸ“¦ å®‰è£…æ›´æ–°

```bash
# æ›´æ–°ä¾èµ–
pip install -r requirements.txt

# å®‰è£…å¼€å‘ä¾èµ–ï¼ˆåŒ…å«æµ‹è¯•å·¥å…·ï¼‰
pip install pytest pytest-cov
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼1ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

1. åˆ›å»ºé…ç½®æ–‡ä»¶ï¼š
```bash
python -c "from llmct.utils.config import Config; Config.create_template('config.yaml')"
```

2. ç¼–è¾‘`config.yaml`å¹¶è®¾ç½®APIå¯†é’¥

3. è¿è¡Œæµ‹è¯•ï¼š
```bash
python mct.py  # è‡ªåŠ¨åŠ è½½config.yaml
```

### æ–¹å¼2ï¼šä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°

```bash
python mct.py --api-key YOUR_KEY --base-url https://api.openai.com
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¹¶å‘æµ‹è¯•withé…ç½®æ–‡ä»¶

```python
from llmct.utils.config import Config
from llmct.core.async_tester import test_models_async
from llmct.core.classifier import ModelClassifier
from llmct.core.reporter import Reporter

# åŠ è½½é…ç½®
config = Config('config.yaml')

# è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆå‡è®¾å·²æœ‰ï¼‰
models = [...]  # ä½ çš„æ¨¡å‹åˆ—è¡¨

# åˆ†ç±»æ¨¡å‹
classifier = ModelClassifier()
model_types = classifier.classify_batch([m['id'] for m in models])

# å¹¶å‘æµ‹è¯•
results = test_models_async(
    api_key=config.get('api.key'),
    base_url=config.get('api.base_url'),
    models=models,
    model_types=model_types,
    max_concurrent=config.get('performance.concurrent', 10)
)

# ä¿å­˜å¤šç§æ ¼å¼
reporter = Reporter(config.get('api.base_url'))
reporter.save_json(results, 'results.json')
reporter.save_html(results, 'results.html')
```

### ç¤ºä¾‹2ï¼šç»“æœåˆ†æå’Œç›‘æ§

```python
from llmct.core.analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()

# 1. è®¡ç®—å¥åº·åº¦
health = analyzer.calculate_health_score(results)
print(f"APIå¥åº·åº¦: {health['score']} ({health['grade']})")

# 2. æ£€æŸ¥å‘Šè­¦
alerts = analyzer.check_alerts(results)
if alerts:
    print("âš ï¸  æ£€æµ‹åˆ°ä»¥ä¸‹é—®é¢˜ï¼š")
    for alert in alerts:
        print(f"  - {alert['message']}")

# 3. å¯¹æ¯”å†å²ç»“æœ
if Path('last_test.json').exists():
    comparison = analyzer.compare_results('last_test.json', 'current_test.json')
    print(f"æ–°å¢å¤±è´¥: {len(comparison['newly_failed'])}")
    print(f"æ¢å¤æ­£å¸¸: {len(comparison['recovered'])}")
```

---

## ğŸ§ª è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_config.py -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=llmct --cov-report=html

# æŸ¥çœ‹è¦†ç›–ç‡æŠ¥å‘Š
open htmlcov/index.html  # Mac/Linux
start htmlcov/index.html  # Windows
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| åŠŸèƒ½ | v1.0 | v2.0 | æå‡ |
|------|------|------|------|
| æµ‹è¯•é€Ÿåº¦ | 25åˆ†é’Ÿ | 5-8åˆ†é’Ÿ | **70%+** |
| é…ç½®ç®¡ç† | ä»…å‘½ä»¤è¡Œ | YAML+ç¯å¢ƒå˜é‡+CLI | **100%** |
| è¾“å‡ºæ ¼å¼ | ä»…TXT | TXT/JSON/CSV/HTML | **4x** |
| é”™è¯¯å¤„ç† | åŸºç¡€ | æ™ºèƒ½é‡è¯•+è‡ªå®šä¹‰å¼‚å¸¸ | **80%** |
| åˆ†æåŠŸèƒ½ | æ—  | å¯¹æ¯”/è¯„åˆ†/å‘Šè­¦ | **âˆ** |
| æµ‹è¯•è¦†ç›–ç‡ | 0% | 80%+ | **âˆ** |

---

## ğŸ”„ å‘åå…¼å®¹æ€§

v2.0å®Œå…¨å‘åå…¼å®¹v1.0çš„å‘½ä»¤è¡Œå‚æ•°å’ŒåŠŸèƒ½ï¼š

```bash
# v1.0çš„å‘½ä»¤åœ¨v2.0ä¸­ä»ç„¶æœ‰æ•ˆ
python mct.py --api-key sk-xxx --base-url https://api.openai.com --only-failed
```

---

## ğŸ“ è¿ç§»æ¸…å•

å¦‚æœä½ æ­£åœ¨ä»v1.0è¿ç§»åˆ°v2.0ï¼š

- [ ] å®‰è£…æ–°çš„ä¾èµ–ï¼š`pip install -r requirements.txt`
- [ ] åˆ›å»ºé…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ï¼šä½¿ç”¨`Config.create_template()`
- [ ] å°†æ•æ„Ÿä¿¡æ¯ï¼ˆAPIå¯†é’¥ï¼‰ç§»åˆ°ç¯å¢ƒå˜é‡
- [ ] å°è¯•å¹¶å‘æµ‹è¯•æ¨¡å¼è·å¾—æ€§èƒ½æå‡
- [ ] ä½¿ç”¨HTMLæ ¼å¼ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
- [ ] è®¾ç½®ç›‘æ§å‘Šè­¦é˜ˆå€¼
- [ ] è¿è¡Œæµ‹è¯•éªŒè¯ï¼š`pytest tests/`

---

## ğŸ› é—®é¢˜æ’æŸ¥

### Q: å¯¼å…¥æ¨¡å—å¤±è´¥

**A**: ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š
```bash
pip install -r requirements.txt
```

### Q: é…ç½®æ–‡ä»¶ä¸ç”Ÿæ•ˆ

**A**: æ£€æŸ¥ï¼š
1. é…ç½®æ–‡ä»¶æ˜¯å¦å‘½åä¸º`config.yaml`ä¸”ä½äºé¡¹ç›®æ ¹ç›®å½•
2. YAMLæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆæ³¨æ„ç¼©è¿›ï¼‰
3. å‘½ä»¤è¡Œå‚æ•°ä¼šè¦†ç›–é…ç½®æ–‡ä»¶

### Q: å¹¶å‘æµ‹è¯•è§¦å‘429é”™è¯¯

**A**: é™ä½å¹¶å‘æ•°ï¼š
```yaml
performance:
  concurrent: 5  # é™ä½å¹¶å‘æ•°
  rate_limit_rpm: 30  # é™ä½é€Ÿç‡é™åˆ¶
```

---

## ğŸ“š æ›´å¤šèµ„æº

- [ä¼˜åŒ–å®æ–½æŒ‡å—](OPTIMIZATION_GUIDE.md)
- [é…ç½®æ–‡ä»¶æ¨¡æ¿](config_template.yaml)
- [å•å…ƒæµ‹è¯•ç¤ºä¾‹](tests/)
- [åŸç‰ˆåŠŸèƒ½æ–‡æ¡£](README.md)

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

å¦‚æœä½ å‘ç°bugæˆ–æœ‰åŠŸèƒ½å»ºè®®ï¼Œè¯·ï¼š
1. åœ¨GitHubä¸Šåˆ›å»ºIssue
2. æè¿°é—®é¢˜å’ŒæœŸæœ›è¡Œä¸º
3. æä¾›å¤ç°æ­¥éª¤ï¼ˆå¦‚é€‚ç”¨ï¼‰

---

**ç‰ˆæœ¬**: v2.0.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-12  
**å‘åå…¼å®¹**: âœ… å®Œå…¨å…¼å®¹v1.0
