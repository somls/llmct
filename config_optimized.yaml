# LLMCT 优化配置文件
# 基于真实API测试结果优化

api:
  # 使用环境变量保护密钥安全
  key: ${LLMCT_API_KEY}
  base_url: https://veloera.wenwen12345.top
  timeout: 20  # 基于实际平均响应时间调整

testing:
  # 测试消息
  message: "hello"
  
  # 跳过已知失败的模型（基于实际测试）
  skip_models:
    - gemma2-9b-it      # HTTP_400 参数错误
    - kimi-k2-auto      # HTTP_404 不存在
    - glm-4.6           # UNKNOWN_ERROR
  
  # 优先测试快速可靠的模型
  priority_models:
    - kimi-k2-fast      # 1.76秒 - 最快
    - gpt-oss-120b      # 2.43秒
    - qwen3-32b         # 2.43秒
    - glm-4.5           # 2.99秒
  
  # 智能测试模式
  only_failed: false
  max_failures: 3       # 跳过失败3次以上的模型
  
  # 跳过特殊类型（可选）
  skip_vision: false
  skip_audio: false

cache:
  enabled: true
  duration_hours: 24
  file: test_cache.db   # 使用SQLite缓存

concurrency:
  # 自适应并发配置（基于测试结果）
  enabled: true
  initial: 15           # 从15开始（响应时间较快）
  min: 5
  max: 30
  
  # 基于速度动态调整
  adjust_based_on_speed: true
  fast_model_threshold: 3.0    # <3秒为快速模型
  slow_model_threshold: 5.0    # >5秒为慢速模型

output:
  format: html          # 支持: txt, json, csv, html
  file: test_report.html
  
  # 输出选项
  show_cache_hits: true
  show_error_details: true
  show_response_time: true

# 高级配置
advanced:
  # 重试策略
  retry:
    max_attempts: 3
    backoff_factor: 2.0
    retry_on: [429, 500, 502, 503, 504]
  
  # 动态超时（基于历史数据）
  dynamic_timeout:
    enabled: true
    fast_models: 10     # 快速模型10秒
    medium_models: 20   # 中速模型20秒  
    slow_models: 30     # 慢速模型30秒
  
  # 模型分组
  groups:
    fast:
      models: [kimi-k2-fast, gpt-oss-120b, qwen3-32b, glm-4.5]
      timeout: 10
    
    claude:
      models: [claude-3-5-haiku-20241022, claude-sonnet-4-20250514, claude-sonnet-4-5-20250929]
      timeout: 15
    
    slow:
      models: [gpt-5, gemini-2.5-pro]
      timeout: 30

# 预设配置文件（通过--profile参数使用）
profiles:
  # 快速检查模式
  fast:
    timeout: 10
    only_models: [kimi-k2-fast, gpt-oss-120b, qwen3-32b, glm-4.5]
    concurrency: 20
  
  # 全面测试模式
  comprehensive:
    timeout: 30
    skip_models: []
    concurrency: 10
  
  # 仅可靠模型
  reliable:
    timeout: 20
    only_models: 
      - kimi-k2-fast
      - kimi-k2
      - gpt-oss-120b
      - qwen3-32b
      - qwen3-coder-480b
      - glm-4.5
      - glm-4.5-flash
    concurrency: 15
