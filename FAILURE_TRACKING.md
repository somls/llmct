# 失败模型追踪功能说明

## 功能概述

失败模型追踪和智能测试功能，可以：
- 自动记录每个模型的失败次数和历史
- 只测试上次失败的模型，节省时间
- 跳过持续失败的模型，避免浪费资源
- 生成详细的失败统计报告

## 核心功能

### 1. 失败次数统计

自动记录每个模型的失败情况：
```json
{
  "model_id": {
    "success": false,
    "failure_count": 5,
    "last_failure": "2025-01-16T10:30:00",
    "failure_history": [
      {"timestamp": "2025-01-16T09:00:00", "error_code": "HTTP_403"},
      {"timestamp": "2025-01-16T09:30:00", "error_code": "HTTP_403"},
      {"timestamp": "2025-01-16T10:00:00", "error_code": "HTTP_403"}
    ]
  }
}
```

**特点：**
- 累计失败次数（不会因为成功而重置）
- 保留最近10次失败记录
- 记录每次失败的时间和错误类型

### 2. 只测试失败模型

使用 `--only-failed` 参数只测试上次失败的模型：

```bash
python test_models.py --api-key sk-xxx --base-url https://api.openai.com --only-failed
```

**效果：**
```
共发现 1132 个模型，筛选出 867 个失败模型进行测试
测试模式: 仅测试失败模型
```

**优势：**
- 第一次测试后，后续只需测试失败的867个模型
- 测试时间从25分钟缩短至5-10分钟
- 减少API调用次数和成本

### 3. 跳过持续失败模型

使用 `--max-failures N` 参数跳过失败次数超过N次的模型：

```bash
# 跳过失败5次以上的模型
python test_models.py --api-key sk-xxx --base-url https://api.openai.com --max-failures 5
```

**输出示例：**
```
gpt-4-deprecated        |     -      |   SKIPPED    | 已跳过(失败5次)
test-model              |     -      |   SKIPPED    | 已跳过(失败8次)
```

**适用场景：**
- 避免重复测试已知不可用的模型
- 节省API配额和测试时间
- 专注于可能恢复的模型

### 4. 组合使用

最佳实践是组合使用两个参数：

```bash
# 只测试失败模型，但跳过失败3次以上的
python test_models.py --api-key sk-xxx --base-url https://api.openai.com --only-failed --max-failures 3
```

**工作流程：**
1. 第一次：全量测试1132个模型
2. 第二次：只测试867个失败模型
3. 第三次：只测试失败模型中失败小于3次的
4. 逐步缩小测试范围

### 5. 持续失败统计报告

自动生成持续失败模型的统计报告：

```
==================================================================================================================
持续失败模型统计 (失败3次以上)
==================================================================================================================

模型ID                                              失败次数       最后错误              最后失败时间             
--------------------------------------------------------------------------------------------------------------
claude-3-5-haiku-20241022                          10           HTTP_403            2025-01-16 10:30:00
gpt-4-deprecated                                   8            HTTP_403            2025-01-16 10:25:00
test-model                                         5            HTTP_429            2025-01-16 10:20:00
dall-e-restricted                                  4            HTTP_403            2025-01-16 10:15:00

总计持续失败模型: 4
==================================================================================================================
```

**信息包含：**
- 模型ID
- 累计失败次数
- 最后一次的错误代码
- 最后失败时间

### 6. 重置失败计数

使用 `--reset-failures` 重置所有失败计数：

```bash
python test_models.py --api-key sk-xxx --base-url https://api.openai.com --reset-failures
```

**场景：**
- API配置更改后
- 模型访问权限更新
- 定期重置计数（如每月）

## 使用场景

### 场景1：日常监控

```bash
# 第一次：全量测试，建立基线
python test_models.py --api-key $KEY --base-url $URL --output day1.txt

# 第二天：只测试失败的
python test_models.py --api-key $KEY --base-url $URL --only-failed --output day2.txt

# 第三天：继续只测试失败的
python test_models.py --api-key $KEY --base-url $URL --only-failed --output day3.txt
```

**效果：**
- 第一天：25分钟，测试1132个
- 第二天：8分钟，测试867个
- 第三天：3-5分钟，测试更少

### 场景2：问题排查

```bash
# 跳过已知长期失败的模型，专注于可能恢复的
python test_models.py --api-key $KEY --base-url $URL --only-failed --max-failures 3
```

**优势：**
- 集中精力在可能修复的模型上
- 避免被长期失败的模型干扰
- 更快发现新问题

### 场景3：定期清理

```bash
# 每月重置一次失败计数
python test_models.py --api-key $KEY --base-url $URL --reset-failures

# 然后做全量测试
python test_models.py --api-key $KEY --base-url $URL --output monthly.txt
```

### 场景4：权限变更后

```bash
# 权限更新后，重置计数重新测试
python test_models.py --api-key $NEW_KEY --base-url $URL --reset-failures --clear-cache
```

## 命令行参数

| 参数 | 说明 | 默认值 | 示例 |
|------|------|--------|------|
| `--only-failed` | 只测试上次失败的模型 | False | `--only-failed` |
| `--max-failures N` | 跳过失败N次以上的模型 | 0（不限制） | `--max-failures 5` |
| `--reset-failures` | 重置所有失败计数 | False | `--reset-failures` |

## 性能对比

### 测试时间

| 测试类型 | 模型数 | 耗时 | 相对首次 |
|---------|--------|------|---------|
| 第1次：全量 | 1132 | 25分钟 | 100% |
| 第2次：仅失败 | 867 | 8分钟 | 32% ⬇️68% |
| 第3次：仅失败+阈值3 | ~300 | 3分钟 | 12% ⬇️88% |
| 第4次：仅失败+阈值5 | ~100 | 1分钟 | 4% ⬇️96% |

### API调用次数

| 测试类型 | API调用 | 相对首次 |
|---------|---------|---------|
| 全量测试 | 1132次 | 100% |
| 仅失败模型 | 867次 | 77% ⬇️23% |
| 仅失败+阈值3 | ~300次 | 27% ⬇️73% |
| 仅失败+阈值5 | ~100次 | 9% ⬇️91% |

### 成本节省

假设API调用费用 $0.005/次，每天测试3次，每月22天：

| 策略 | 每月调用 | 每月成本 | 节省 |
|------|---------|---------|------|
| 全量测试 | 74,712 | $373.56 | - |
| 仅失败 | 57,156 | $285.78 | $87.78 (23%) |
| 仅失败+阈值3 | 19,800 | $99.00 | $274.56 (73%) |
| 仅失败+阈值5 | 6,600 | $33.00 | $340.56 (91%) |

## 输出变化

### 统计信息增强

```
测试完成 | 总计: 867 | 成功: 0 | 失败: 767 | 跳过: 100 | 缓存命中: 0 | 成功率: 0.0%
```

新增字段：
- **跳过**: 因失败次数过多被跳过的模型数

### 缓存信息增强

```
[信息] 缓存已保存 (共 1132 条记录)
[信息] 失败模型: 867 个，持续失败(≥3次): 520 个
```

新增信息：
- 失败模型总数
- 持续失败模型数（失败≥3次）

### 新增持续失败统计

只在全量测试时显示：
```
==================================================================================================================
持续失败模型统计 (失败3次以上)
==================================================================================================================

模型ID                                              失败次数       最后错误              最后失败时间             
--------------------------------------------------------------------------------------------------------------
claude-3-5-haiku-20241022                          10           HTTP_403            2025-01-16 10:30:00
...

总计持续失败模型: 520
==================================================================================================================
```

## 缓存结构变化

### 新增字段

```json
{
  "model_id": {
    "success": bool,
    "response_time": float,
    "error_code": str,
    "content": str,
    "timestamp": str,
    "failure_count": int,           // 新增：累计失败次数
    "last_failure": str,            // 新增：最后失败时间
    "failure_history": [            // 新增：失败历史记录（最多10条）
      {
        "timestamp": str,
        "error_code": str
      }
    ]
  }
}
```

### 向后兼容

- 旧版缓存文件可以正常加载
- 缺失的字段会自动初始化为默认值
- 不影响现有功能

## 最佳实践

### 1. 渐进式测试策略

```bash
# 周一：全量测试，重置计数
python test_models.py --api-key $KEY --base-url $URL --reset-failures --output mon.txt

# 周二-周五：只测试失败模型
python test_models.py --api-key $KEY --base-url $URL --only-failed --output tue.txt

# 专注测试：跳过持续失败的
python test_models.py --api-key $KEY --base-url $URL --only-failed --max-failures 3
```

### 2. 设置合理的阈值

根据API稳定性设置阈值：

| API稳定性 | 推荐阈值 | 说明 |
|----------|---------|------|
| 高（正式环境） | 5-10 | 失败5次以上大概率长期不可用 |
| 中（测试环境） | 3-5 | 失败3次以上值得跳过 |
| 低（开发环境） | 不设置 | 环境不稳定，不建议跳过 |

### 3. 定期重置

```bash
# 每月第一天重置
if [ $(date +%d) -eq 01 ]; then
  python test_models.py --api-key $KEY --base-url $URL --reset-failures
fi
```

### 4. 监控失败趋势

保存每次的持续失败报告：
```bash
python test_models.py --api-key $KEY --base-url $URL > test_$(date +%Y%m%d).log
```

对比不同日期的失败模型数量，监控趋势。

## 注意事项

1. **失败计数不会自动重置**
   - 即使模型测试成功，失败计数也会保留
   - 需要手动使用 `--reset-failures` 重置

2. **跳过的模型不计入错误统计**
   - SKIPPED 不会出现在错误统计报告中
   - 不会影响成功率计算

3. **持续失败统计只在全量测试时显示**
   - 使用 `--only-failed` 时不显示该报告
   - 避免重复显示相同信息

4. **失败历史最多保留10条**
   - 自动保留最近的10次失败记录
   - 节省缓存文件大小

5. **SKIPPED模型仍在结果文件中**
   - 被跳过的模型会记录在输出文件
   - 便于追踪哪些模型被跳过

## 故障排查

### Q1: 为什么 --only-failed 没有筛选出失败模型？

**A:** 检查以下情况：
1. 是否之前运行过测试？（需要先有缓存记录）
2. 是否清除了缓存？（`--clear-cache` 会清空失败记录）
3. 是否所有模型都成功了？

### Q2: 失败次数一直在增加？

**A:** 这是正常的。失败计数是累计的，不会因为成功而重置。如需重置，使用 `--reset-failures`。

### Q3: --max-failures 不生效？

**A:** 确保：
1. 设置了大于0的值
2. 启用了缓存（不要使用 `--no-cache`）
3. 模型的失败次数确实达到阈值

### Q4: 持续失败统计没有显示？

**A:** 检查：
1. 是否使用了 `--only-failed`？（该模式不显示持续失败统计）
2. 是否有失败次数≥3的模型？
3. 是否启用了缓存？

---

**相关文档**: README.md, USAGE_GUIDE.md
