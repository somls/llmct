#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
v2.4.0 åŠŸèƒ½æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºæ–°å¢çš„æŒ‰ base_url åˆ†ç±»ä¿å­˜å’Œç»Ÿè®¡åˆ†æåŠŸèƒ½
"""

import json
import os
import sys
import shutil
from pathlib import Path
from datetime import datetime

# è®¾ç½® Windows æ§åˆ¶å°ç¼–ç 
if sys.platform == 'win32':
    import codecs
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    if hasattr(sys.stderr, 'buffer'):
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

from llmct.core.reporter import Reporter
from llmct.core.analyzer import ResultAnalyzer


def print_section(title):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def demo_step_1_create_mock_data():
    """æ­¥éª¤1: åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®"""
    print_section("æ­¥éª¤ 1: åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®")
    
    # æ¸…ç†æ—§æ•°æ®
    demo_dir = Path('demo_test_results')
    if demo_dir.exists():
        shutil.rmtree(demo_dir)
        print("âœ“ æ¸…ç†æ—§çš„æ¼”ç¤ºæ•°æ®")
    
    # ä¿®æ”¹å·¥ä½œç›®å½•ä»¥ä½¿ç”¨ demo_test_results
    os.makedirs(demo_dir, exist_ok=True)
    os.chdir(demo_dir)
    
    # åˆ›å»º3æ¬¡æ¨¡æ‹Ÿæµ‹è¯•
    base_url = 'https://api.demo.com'
    reporter = Reporter(base_url)
    
    print(f"æ¨¡æ‹Ÿ API: {base_url}")
    print(f"ç”Ÿæˆ 3 æ¬¡æµ‹è¯•ç»“æœ...\n")
    
    test_files = []
    
    for day in range(1, 4):
        # æ¨¡æ‹Ÿæµ‹è¯•ç»“æœï¼ˆé€æ¸æ”¹å–„ï¼‰
        results = [
            {
                'model': 'gpt-4',
                'success': True,
                'response_time': 1.2 - day * 0.1,  # é€æ¸å˜å¿«
                'error_code': '',
                'content': f'Response from gpt-4 (test {day})'
            },
            {
                'model': 'gpt-3.5-turbo',
                'success': day >= 2,  # ç¬¬1å¤©å¤±è´¥ï¼Œåé¢æˆåŠŸ
                'response_time': 0.8 if day >= 2 else 0,
                'error_code': '' if day >= 2 else 'HTTP_403',
                'content': f'Response from gpt-3.5-turbo' if day >= 2 else ''
            },
            {
                'model': 'text-embedding-ada-002',
                'success': True,
                'response_time': 0.4,
                'error_code': '',
                'content': 'Embedding generated'
            }
        ]
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        output_file = reporter.save_report(
            results,
            f'demo_test_{day}.json',
            format='json'
        )
        test_files.append(output_file)
        
        print(f"  ç¬¬ {day} æ¬¡æµ‹è¯•: {output_file}")
    
    print(f"\nâœ“ æˆåŠŸç”Ÿæˆ {len(test_files)} ä¸ªæµ‹è¯•ç»“æœæ–‡ä»¶")
    
    # è¿”å›ä¸Šçº§ç›®å½•
    os.chdir('..')
    
    return test_files


def demo_step_2_analyze_results():
    """æ­¥éª¤2: åˆ†ææµ‹è¯•ç»“æœ"""
    print_section("æ­¥éª¤ 2: åˆ†ææµ‹è¯•ç»“æœ")
    
    base_url_dir = 'demo_test_results/test_results/api.demo.com'
    
    if not Path(base_url_dir).exists():
        print("âœ— æµ‹è¯•ç»“æœç›®å½•ä¸å­˜åœ¨")
        return
    
    analyzer = ResultAnalyzer()
    
    print(f"æ­£åœ¨åˆ†æ: {base_url_dir}\n")
    
    # æ‰§è¡Œåˆ†æ
    analysis = analyzer.analyze_by_base_url(base_url_dir)
    
    if 'error' in analysis:
        print(f"âœ— åˆ†æå¤±è´¥: {analysis['error']}")
        return
    
    # æ‰“å°æ€»ä½“ç»Ÿè®¡
    summary = analysis['summary']
    print("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  æµ‹è¯•æ–‡ä»¶æ•°: {summary['total_test_files']}")
    print(f"  æ¨¡å‹æ€»æ•°: {summary['total_models']}")
    
    # æ‰“å°æ¨¡å‹ç»Ÿè®¡
    print("\nğŸ“ˆ æ¨¡å‹ç»Ÿè®¡:")
    model_stats = analysis['model_statistics']
    
    for model_name, stats in model_stats.items():
        print(f"\n  {model_name}:")
        print(f"    æ€»æµ‹è¯•: {stats['total_tests']} | æˆåŠŸ: {stats['success_tests']} | å¤±è´¥: {stats['failed_tests']}")
        print(f"    æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"    å¹³å‡å“åº”æ—¶é—´: {stats['avg_response_time']:.2f}ç§’")
        
        if stats['error_codes']:
            print(f"    é”™è¯¯åˆ†å¸ƒ: {stats['error_codes']}")
    
    print("\nâœ“ åˆ†æå®Œæˆ")
    
    return analysis


def demo_step_3_get_rankings():
    """æ­¥éª¤3: è·å–æˆåŠŸç‡æ’å"""
    print_section("æ­¥éª¤ 3: è·å–æˆåŠŸç‡æ’å")
    
    base_url_dir = 'demo_test_results/test_results/api.demo.com'
    
    analyzer = ResultAnalyzer()
    
    print(f"è®¡ç®—æ¨¡å‹æˆåŠŸç‡æ’å...\n")
    
    ranked = analyzer.get_model_success_rates(base_url_dir, min_tests=1)
    
    if not ranked:
        print("âœ— æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®")
        return
    
    # æ‰“å°æ’åè¡¨æ ¼
    print("ğŸ† æ¨¡å‹æˆåŠŸç‡æ’å:")
    print()
    print(f"{'æ’å':<6} {'æ¨¡å‹åç§°':<30} {'æµ‹è¯•æ¬¡æ•°':<10} {'æˆåŠŸç‡':<10} {'å¹³å‡å“åº”æ—¶é—´':<12}")
    print("-" * 80)
    
    for rank, model in enumerate(ranked, 1):
        print(f"{rank:<6} {model['model']:<30} {model['total_tests']:<10} "
              f"{model['success_rate']:>6.1f}%    {model['avg_response_time']:>8.2f}ç§’")
    
    print("\nâœ“ æ’åè®¡ç®—å®Œæˆ")
    
    return ranked


def demo_step_4_save_report():
    """æ­¥éª¤4: ä¿å­˜åˆ†ææŠ¥å‘Š"""
    print_section("æ­¥éª¤ 4: ä¿å­˜åˆ†ææŠ¥å‘Š")
    
    base_url_dir = 'demo_test_results/test_results/api.demo.com'
    
    analyzer = ResultAnalyzer()
    
    print(f"ç”Ÿæˆåˆ†ææŠ¥å‘Š...\n")
    
    output_file = analyzer.save_base_url_analysis(base_url_dir)
    
    if output_file:
        print(f"âœ“ åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        
        # è¯»å–å¹¶æ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        with open(output_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"\næŠ¥å‘Šå†…å®¹é¢„è§ˆ:")
        print(f"  - æµ‹è¯•æ–‡ä»¶æ•°: {data['summary']['total_test_files']}")
        print(f"  - æ¨¡å‹æ€»æ•°: {data['summary']['total_models']}")
        print(f"  - åŒ…å«è¯¦ç»†çš„æ¨¡å‹ç»Ÿè®¡å’Œæµ‹è¯•å†å²")
    
    return output_file


def demo_step_5_show_insights():
    """æ­¥éª¤5: å±•ç¤ºåˆ†ææ´å¯Ÿ"""
    print_section("æ­¥éª¤ 5: åˆ†ææ´å¯Ÿ")
    
    base_url_dir = 'demo_test_results/test_results/api.demo.com'
    
    analyzer = ResultAnalyzer()
    analysis = analyzer.analyze_by_base_url(base_url_dir)
    
    if 'error' in analysis:
        print("âœ— æ— æ³•ç”Ÿæˆæ´å¯Ÿ")
        return
    
    model_stats = analysis['model_statistics']
    
    print("ğŸ’¡ å…³é”®å‘ç°:\n")
    
    # 1. æœ€ç¨³å®šçš„æ¨¡å‹
    most_stable = max(model_stats.items(), key=lambda x: x[1]['success_rate'])
    print(f"1. æœ€ç¨³å®šçš„æ¨¡å‹:")
    print(f"   {most_stable[0]} (æˆåŠŸç‡: {most_stable[1]['success_rate']:.1f}%)")
    
    # 2. æœ€å¿«çš„æ¨¡å‹
    successful_models = {k: v for k, v in model_stats.items() if v['avg_response_time'] > 0}
    if successful_models:
        fastest = min(successful_models.items(), key=lambda x: x[1]['avg_response_time'])
        print(f"\n2. å“åº”æœ€å¿«çš„æ¨¡å‹:")
        print(f"   {fastest[0]} (å¹³å‡å“åº”: {fastest[1]['avg_response_time']:.2f}ç§’)")
    
    # 3. æ”¹å–„è¶‹åŠ¿
    for model_name, stats in model_stats.items():
        if stats['success_rate'] > 0 and stats['success_rate'] < 100:
            history = stats['test_history']
            if len(history) >= 2:
                recent_success = history[-1]['success']
                early_success = history[0]['success']
                if recent_success and not early_success:
                    print(f"\n3. æ”¹å–„è¶‹åŠ¿:")
                    print(f"   {model_name} ä»å¤±è´¥å˜ä¸ºæˆåŠŸ")
    
    print("\nâœ“ æ´å¯Ÿåˆ†æå®Œæˆ")


def cleanup_demo():
    """æ¸…ç†æ¼”ç¤ºæ•°æ®"""
    print_section("æ¸…ç†æ¼”ç¤ºæ•°æ®")
    
    demo_dir = Path('demo_test_results')
    if demo_dir.exists():
        shutil.rmtree(demo_dir)
        print("âœ“ å·²æ¸…ç†æ‰€æœ‰æ¼”ç¤ºæ•°æ®")
    else:
        print("âœ“ æ— éœ€æ¸…ç†")


def main():
    """ä¸»å‡½æ•°"""
    print("\n")
    print("â•”" + "="*78 + "â•—")
    print("â•‘" + " "*25 + "v2.4.0 åŠŸèƒ½æ¼”ç¤º" + " "*38 + "â•‘")
    print("â•š" + "="*78 + "â•")
    
    try:
        # æ‰§è¡Œæ¼”ç¤ºæ­¥éª¤
        demo_step_1_create_mock_data()
        demo_step_2_analyze_results()
        demo_step_3_get_rankings()
        demo_step_4_save_report()
        demo_step_5_show_insights()
        
        # æ€»ç»“
        print_section("æ¼”ç¤ºæ€»ç»“")
        print("âœ… æ‰€æœ‰åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
        print()
        print("æ–°åŠŸèƒ½äº®ç‚¹:")
        print("  1. âœ… æµ‹è¯•ç»“æœè‡ªåŠ¨æŒ‰ base_url åˆ†ç±»ä¿å­˜")
        print("  2. âœ… ç»Ÿè®¡åŒä¸€æ¨¡å‹å¤šæ¬¡æµ‹è¯•çš„æˆåŠŸç‡")
        print("  3. âœ… è‡ªåŠ¨è®¡ç®—å¹³å‡å“åº”æ—¶é—´å’Œé”™è¯¯åˆ†å¸ƒ")
        print("  4. âœ… ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š")
        print("  5. âœ… æä¾›æˆåŠŸç‡æ’åå’Œæ€§èƒ½æ´å¯Ÿ")
        print()
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†
        print("æ¼”ç¤ºæ•°æ®ä½äº demo_test_results/ ç›®å½•")
        response = input("\næ˜¯å¦æ¸…ç†æ¼”ç¤ºæ•°æ®? (y/n): ").strip().lower()
        
        if response == 'y':
            cleanup_demo()
        else:
            print("\nâœ“ æ¼”ç¤ºæ•°æ®å·²ä¿ç•™ï¼Œæ‚¨å¯ä»¥æ‰‹åŠ¨æŸ¥çœ‹")
        
    except Exception as e:
        print(f"\nâœ— æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\næ„Ÿè°¢ä½¿ç”¨ï¼\n")


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\næ¼”ç¤ºå·²å–æ¶ˆ")
        cleanup_demo()
